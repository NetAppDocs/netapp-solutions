---
sidebar: sidebar
permalink: ai/aicp_introduction.html
keywords: tr-4798, tr4798, 4798, NetApp AI, Machine, Deep learning, introduction
summary: This report shows you how to rapidly clone a data namespace. It demonstrates how to define and implement AI training workflows that incorporate the near-instant creation of data and model baselines for traceability and versioning. It also shows how to seamlessly replicate data across sites and regions and swiftly provision Jupyter Notebook workspaces with access to massive datasets.
---

= TR-4798: NetApp AI Control Plane
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./../media/

//
// This file was created with NDAC Version 2.0 (August 17, 2020)
//
// 2020-08-18 15:53:11.466360
//

Mike Oglesby, NetApp

[.lead]
Companies and organizations of all sizes and across many industries are turning to artificial intelligence (AI), machine learning (ML), and deep learning (DL) to solve real-world problems, deliver innovative products and services, and to get an edge in an increasingly competitive marketplace. As organizations increase their use of AI, ML, and DL, they face many challenges, including workload scalability and data availability. This document demonstrates how you can address these challenges by using the NetApp AI Control Plane, a solution that pairs NetApp data management capabilities with popular open-source tools and frameworks.

This report shows you how to rapidly clone a data namespace. It also shows you how to seamlessly replicate data across sites and regions to create a cohesive and unified AI/ML/DL data pipeline. Additionally, it walks you through the defining and implementing of AI, ML, and DL training workflows that incorporate the near-instant creation of data and model baselines for traceability and versioning. With this solution, you can trace every model training run back to the exact dataset that was used to train and/or validate the model. Lastly, this document shows you how to swiftly provision Jupyter Notebook workspaces with access to massive datasets.

Note: For HPC style distributed training at scale involving a large number of GPU servers that require shared access to the same dataset, or if you require/prefer a parallel file system, check out link:https://www.netapp.com/pdf.html?item=/media/31317-tr-4890.pdf[TR-4890^]. This technical report describes how to include link:https://blog.netapp.com/solution-support-for-beegfs-and-e-series/[NetApp's fully supported parallel file system solution BeeGFS^] as part of the NetApp AI Control Plane. This solution is designed to scale from a handful of NVIDIA DGX A100 systems, up to a full blown 140 node SuperPOD.

The NetApp AI Control Plane is targeted towards data scientists and data engineers, and, thus, minimal NetApp or NetApp ONTAPÂ® expertise is required. With this solution, data management functions can be executed using simple and familiar tools and interfaces. If you already have NetApp storage in your environment, you can test drive the NetApp AI Control plane today. If you want to test drive the solution but you do not have already have NetApp storage, visit http://cloud.netapp.com/[cloud.netapp.com^], and you can be up and running with a cloud-based NetApp storage solution in minutes. The following figure provides a visualization of the solution.

image:aicp_image1.png[Error: Missing Graphic Image]

link:aicp_concepts_and_components.html[Next: Concepts and Components.]
