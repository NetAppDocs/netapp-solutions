---
sidebar: sidebar
permalink: ai/aipod_nv_hw_components.html
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX
summary: NetApp AI Pod with NVIDIA DGX Systems - Hardware Components
---

= NetApp AI Pod with NVIDIA DGX Systems - Hardware Components
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./../media/

link:aipod_nv_intro.html[Previous: NetApp AI Pod with NVIDIA DGX Systems - Introduction.]

== NetApp AFF Storage Systems

NetApp AFF state-of-the-art storage systems enable IT departments to meet enterprise storage requirements with industry-leading performance, superior flexibility, cloud integration, and best-in-class data management. Designed specifically for flash, AFF systems help accelerate, manage, and protect business-critical data.

=== AFF A-series storage systems

UPDATE FOR A900!!!


The NetApp AFF A800 system is the industry’s first end-to-end NVMe solution. For NAS workloads, a single AFF A800 system supports throughput of 25GBps for sequential reads and one million IOPS for small random reads at sub-500µs latencies. 

image:oai_A800_3D.png[Error: Missing Graphic Image]

AFF A800 systems support the following features:
* Massive throughput of up to 300GBps and 11.4 million IOPS in a 24-node cluster
* 100GbE and 32Gb FC connectivity
* Up to 30TB solid-state drives (SSDs) with multistream write
* High density with 2PB in a 2U drive shelf
* Scaling from 200TB (2 controllers) to 9.6PB (24 controllers)
* NetApp ONTAP includes a complete suite of data protection and replication features for industry-leading data management

For the largest deployments, AFF A900 systems offer higher performance and capacity options while other NetApp storage systems, such as the AFF A700, AFF A400, and AFF A250, offer options for smaller deployments at lower cost points. 

== NVIDIA DGX BasePOD
DGX BasePOD is an integrated solution consisting of NVIDIA hardware and software components, MLOps solutions, and third-party storage. Leveraging best practices of scale-out system design with NVIDIA products and validated partner solutions, customers can implement an efficient and manageable platform for AI development. Figure 1 highlights the various components of NVIDIA DGX BasePOD.

image:oai_basepod_layers.png[Error: Missing Graphic Image]

=== NVIDIA DGX H100 System
The DGX&#8482; H100 system is the latest iteration of DGX Systems and the AI powerhouse that is accelerated by the groundbreaking performance of the NVIDIA H100 GPU.

image:oai_H100_3D.png[Error: Missing Graphic Image]

Key specifications of the DGX H100 system are:
* Eight NVIDIA H100 GPUs.
* 80 GB GPU memory.
* Four NVIDIA NVSwitch™ chips.
* Dual 56-core fourth Gen Intel® Xeon® capable processors with PCIe 5.0 support.
* 2 TB of DDR5 system memory.
* Four OSFP ports serving eight single-port NVIDIA ConnectX-7 VPI, three dual-port NVIDIA ConnectX-7 VPI.
* Two 1.92 TB M.2 NVMe drives for DGX OS, eight 3.84 TB U.2 NVMe drives for storage/cache.
* 11.3 kW max power.
The rear ports of the DGX H100 CPU tray are shown in Figure 7. Four of the OSFP ports serve eight ConnectX-7 HCAs for the InfiniBand compute fabric. Each pair of dual-port ConnectX-7 HCAs provide parallel pathways to the storage and management fabrics. The out-of-band port is used for BMC access.
image:oai_H100_rear.png[Error: Missing Graphic Image]

=== NVIDIA DGX A100 System
The NVIDIA DGX A100 system offers unprecedented compute density, performance, and flexibility in the world’s first 5 petaFLOPS AI system.

image:oai_A100_3D.png[Error: Missing Graphic Image]

Key specifications of the DGX A100 system are:
* Eight NVIDIA A100 Tensor Core GPUs.
* 40 GB or 80 GB GPU memory options.
* Six NVIDIA NVSwitch™ chips.
* Dual AMD EPYC™ 7742 CPUs, 128 total cores, 2.25 GHz (base), 3.4 GHz (max boost).
* Up to 2 TB of system memory.
* Eight NVIDIA ConnectX-6 or ConnectX-7 InfiniBand HCAs.
* Two 1.92 TB M.2 NVMe drives for DGX OS, eight 3.84 TB U.2 NVMe drives for storage/cache.
* 6.5 kW max power.

More information about DGX A100 systems is available link:https://www.nvidia.com/en-us/data-center/dgx-a100/[here].

The rear ports of the DGX A100 CPU tray are shown in Figure 5. Four of the single-port HCAs are used for the InfiniBand compute fabrics. Each pair of dual-port HCAs provide parallel pathways to the storage and management fabrics. The out-of-band port is used for BMC access.
image:oai_A100_rear.png[Error: Missing Graphic Image]


=== NVIDIA Networking
==== NVIDIA QM9700 Switch

image:oai_QM9700.png[Error: Missing Graphic Image]

NVIDIA QM9700 switches with NDR InfiniBand connectivity power the compute fabric in NDR BasePOD configurations. ConnectX-7 single-port adapters are used for the InfiniBand compute fabric. Each NVIDIA DGX system has dual connections to each QM9700 switch, providing multiple high-bandwidth, low-latency paths between 
the systems.

==== NVIDIA QM8700 Switch

image:oai_QM8700.png[Error: Missing Graphic Image]

NVIDIA QM8700 switches with HDR InfiniBand connectivity power the compute fabric in HDR BasePOD configurations. ConnectX-6 single-port adapters are used for the InfiniBand compute fabric. Each NVIDIA DGX system has dual connections to each QM8700 switch providing multiple high-bandwidth, low-latency paths between the systems.

==== NVIDIA SN4600 Switch

image:oai_SN4600.png[Error: Missing Graphic Image]

NVIDIA SN4600 switches offer 128 total ports (64 per switch) to provide redundant connectivity for in-band management of the DGX BasePOD. The NVIDIA SN4600 switch can provide for speeds between 1 GbE and 200 GbE.For storage appliances connected over Ethernet, the NVIDIA SN4600 switches are also used. The ports on the NVIDIA DGX dual-port HCAs are used for both in-band management and storage connectivity.

==== NVIDIA SN2201 Switch

image:oai_SN2201.png[Error: Missing Graphic Image]

NVIDIA SN2201 switches offer 48 ports to provide connectivity for out-of-band management. Out-of-band management provides consolidated management connectivity for all components in BasePOD. 

==== NVIDIA Connect-X 7 HCA

image:oai_CX7.png[Error: Missing Graphic Image]

The ConnectX-7 HCA is the latest ConnectX HCA line. It can provide 25/50/100/200/400G of throughput. NVIDIA DGX systems use both the single and dual-port ConnectX-7 HCAs to provide flexibility in DGX BasePOD deployments with NDR. Additional specifications are available here.

==== NVIDIA Connect-X 6 HCA

image:oai_CX6.png[Error: Missing Graphic Image]

ConnectX-6 HCAs can provide 10/25/40/50/100/200G of throughput. NVIDIA DGX systems use both the single and dual-port ConnectX-6 HCAs to provide flexibility in DGX BasePOD deployments with HDR.



link:aipod_nv_sw_components.html[Next: NetApp AI Pod with NVIDIA DGX Systems - Software Components.]