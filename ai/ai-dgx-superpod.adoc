---
sidebar: sidebar
permalink: ai/ai-dgx-superpod.html
keywords: netapp, aipod, nvidia, dgx superpod, ai solution, design
summary: This NetApp Verified Architecture describes the design of the NVIDIA DGX SuperPOD with NetApp® BeeGFS building blocks. This solution is a full-stack data center platform that is validated on a dedicated acceptance cluster at NVIDIA.

---
//NVIDIA DGX SuperPOD with NetApp
== NetApp AIPod with NVIDIA DGX SuperPOD
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./../media/

David Arnette, NetApp
Sathish Thyagarajan, NetApp


== Executive summary

Although AI enhances consumers’ lives and helps organizations in all industries worldwide to innovate and to grow their businesses, it is a disrupter for IT. To support the business, IT departments are scrambling to deploy high-performance computing (HPC) solutions that can meet the extreme demands of AI workloads. As the race to win with AI intensifies, the need for an easy-to-deploy, easy-to-scale, and easy-to-manage solution becomes increasingly urgent. 

The NVIDIA DGX SuperPOD makes supercomputing infrastructure easily accessible for your organization and delivers the extreme computational power that you need to solve even the most complex AI problems. To help you deploy at scale today, this NVIDIA and NetApp turnkey solution removes the complexity and guesswork from infrastructure design and delivers a complete, validated solution including best-in-class compute, networking, storage, and software. 

== Program summary 

NVIDIA DGX SuperPOD with NVIDIA DGX H100 systems and NVIDIA Base Command brings together a design-optimized combination of AI computing, network fabric, storage, software, and support. The BeeGFS on NetApp architecture was originally validated on a dedicated acceptance cluster at NVIDIA. The latest architecture extends this validation by maintaining the proven design while incorporating support for the latest hardware from NVIDIA.

== Solution overview

NVIDIA DGX SuperPOD is an AI data center infrastructure platform delivered as a turnkey solution for IT to support the most complex AI workloads facing today’s enterprises. It simplifies deployment and management while delivering virtually limitless scalability for performance and capacity. In other words, DGX SuperPOD lets you focus on insights instead of infrastructure.
With NetApp EF600 all-flash arrays at the foundation of your NVIDIA DGX SuperPOD, you get an agile AI solution that scales easily and seamlessly. The flexibility and scalability of the solution enable it to support and adapt to evolving workloads, making it a strong foundation to meet your future storage requirements. Modular storage building blocks give you a granular approach to growth. You can scale seamlessly from terabytes to petabytes. By increasing the number of storage building blocks, you can scale up the performance and capacity of the file system, enabling your solution to manage the most extreme workloads with ease. 

=== Solution technology

* NVIDIA DGX SuperPOD with NVIDIA DGX H100 systems is established on the foundation of a previously validated model with NVIDIA DGX A100 systems, which validated a deployment of 20 – 140 x DGX A100 systems with validated externally attached shared storage:
** Each DGX SuperPOD scalable unit (SU) consists of 32 DGX H100 systems and is capable of 640 petaFLOPS of AI performance at FP8 precision. It usually contains at least two NetApp BeeGFS building blocks depending on the performance and capacity requirements for a particular installation.

* NetApp BeeGFS building blocks consists of two NetApp EF600 arrays and two x86 servers:
** With NetApp EF600 all-flash arrays at the foundation of your NVIDIA DGX SuperPOD, you get a reliable storage foundation backed by six 9s of uptime. 
** The file system layer between the NetApp EF600 and the NVIDIA DGX H100 systems is the BeeGFS parallel file system. BeeGFS was created by the Fraunhofer Center for High-Performance Computing in Germany to solve the pain points of legacy parallel file systems. The result is a file system with a modern, user space architecture that is now developed and delivered by ThinkParQ and used by many supercomputing environments. 
** NetApp support for BeeGFS places the assistance of NetApp’s excellent support organization at your fingertips. You get access to superior support resources, early access to BeeGFS releases, and access to select BeeGFS enterprise features such as quota enforcement and high availability (HA).
* The combination of NVIDIA SuperPOD SUs and NetApp BeeGFS building blocks provides an agile AI solution in which compute or storage scales easily and seamlessly.
Figure 1 shows a high-level view of the NVIDIA DGX SuperPOD with NetApp solution.
Figure 1) A high-level view of the solution.

Figure 2 shows the frontal view of a default sized NVIDIA DGX SuperPOD system.
Figure 2) Front view single SU rack layout.
 
Figure 3 shows an overview of a NetApp BeeGFS building block.
Figure 3) NetApp BeeGFS building block.

=== Power requirements
Power requirements depend on the performance and capacity requirements for a particular installation. A default starting configuration 32 node SuperPOD with the recommended BeeGFS storage blocks requiresrequire up to approximately 326,4kW maximum power. See the NVIDIA DGX SuperPOD Data Center Design Reference Guide for a full compute breakdown of thermal and power requirements. 

=== Software requirements
Table 2 lists the software components required to implement the solution. The software components that are used in any particular implementation of the solution might vary based on customer requirements.
Table 2) Software requirements.
Software
NVIDIA DGX software stack
NVIDIA Base Command Manager
ThinkParQ BeeGFS parallel file system

== Solution verification

NVIDIA DGX SuperPOD with NetApp was validated on a dedicated acceptance cluster at NVIDIA by using NetApp BeeGFS building blocks. Acceptance criteria was based on a series of application, performance, and stress tests performed by NVIDIA. For more information, see the NVIDIA DGX SuperPOD: NetApp EF600 and BeeGFS Reference Architecture.

== Conclusion
NetApp and NVIDIA have a long history of collaboration to deliver a portfolio of AI solutions to market. NVIDIA DGX SuperPOD with the NetApp EF600 all-flash array is a proven, validated solution that you can deploy with confidence. This fully integrated, turnkey architecture takes the risk out of deployment and puts you on the path to winning the race to AI leadership. 

== Where to find additional information
To learn more about the information that is described in this document, review the following documents and/or websites:
NVA-1164-DESIGN: BeeGFS on NetApp NVA Design
https://www.netapp.com/media/71123-nva-1164-design.pdf
NVA-1164-DEPLOY: BeeGFS on NetApp NVA Deployment
https://www.netapp.com/media/71124-nva-1164-deploy.pdf
NVIDIA DGX SuperPOD Reference Architecture
https://docs.nvidia.com/dgx-superpod/reference-architecture-scalable-infrastructure-h100/latest/index.html#
NVIDIA DGX SuperPOD: NetApp EF600 and BeeGFS
https://nvidiagpugenius.highspot.com/viewer/62915e2ef093f1a97b2d1fe6?iid=62913b14052a903cff46d054&source=email.62915e2ef093f1a97b2d1fe7.4
