---
sidebar: sidebar
permalink: ai/aipod_nv_validation_sizing.html
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX
summary: NetApp AIPod with NVIDIA DGX Systems - Solution Validation and Sizing Guidance
---

= NetApp AIPod with NVIDIA DGX Systems - Solution Validation and Sizing Guidance
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./../media/

[.lead]
This section focuses on the solution validation and sizing guidance for the NetApp AIPod with NVIDIA DGX systems.

== Solution Validation

The storage configuration in this solution was validated using a series of synthetic workloads using the open-source tool FIO. These tests include read and write I/O patterns intended to simulate the storage workload generated by DGX systems performing deep learning training jobs. The storage configuration was validated using a cluster of 2-socket CPU servers running the FIO workloads concurrently to simulate a cluster of DGX systems. Each client was configured with the same network configuration described previously, with the addition of the following details.

RESULTS for FIO TESTING!!


OTHER TEST RESULTS?? GDSIO??

== Storage System Sizing Guidance

NetApp has successfully completed the DGX BasePOD certification, and the two A90 HA pairs as tested can easily support a cluster of sixteen DGX H100 systems. For larger deployments with higher storage performance requirements, additional AFF systems can be added to the NetApp ONTAP cluster up to 12 HA pairs (24 nodes) in a single cluster. Using the FlexGroup technology described in this solution, a 24-node cluster can provide over 40 PB and up to 300 GBps throughput in a single namespace. Other NetApp storage systems such as the AFF A400, A250 and C800 offer lower performance and/or higher capacity options for smaller deployments at lower cost points. Because ONTAP 9 supports mixed-model clusters, customers can start with a smaller initial footprint and add more or larger storage systems to the cluster as capacity and performance requirements grow. The table below shows a rough estimate of the number of A100 and H100 GPUs supported on each AFF model.

_NetApp storage system sizing guidance_
image:aipod_nv_sizing_new.png[Error: Missing Graphic Image]
