---
sidebar: sidebar
permalink: ai/aipod_nv_validation_sizing.html
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX
summary: NetApp AIPod with NVIDIA DGX Systems - Solution Validation and Sizing Guidance
---

= NetApp AIPod with NVIDIA DGX H100 Systems - Solution Validation and Sizing Guidance
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./../media/

[.lead]
This section focuses on the solution validation and sizing guidance for the NetApp AIPod with NVIDIA DGX systems.

== Solution Validation

The storage configuration in this solution was validated using a series of synthetic workloads using the open-source tool FIO. These tests include read and write I/O patterns intended to simulate the storage workload generated by DGX systems performing deep learning training jobs. The storage configuration was validated using a cluster of 2-socket CPU servers running the FIO workloads concurrently to simulate a cluster of DGX systems. Each client was configured with the same network configuration described previously.

The graph below shows the performance for 2 AFF A90 systems (4 controllers) compared to 2 AFF A900 systems. The AFF A90 system has significantly higher performance than the A900, reaching over 90 GB/s for sequential read throughput. 

_A90 vs. A900- sequential read throughput_
image:aipod_nv_A90_testresult.png[Error: Missing Graphic Image]



== Storage System Sizing Guidance

NetApp has successfully completed the DGX BasePOD certification, and the two A90 HA pairs as tested have been validated to support a cluster of sixteen DGX H100 systems. For larger deployments with higher storage performance requirements, additional AFF systems can be added to the NetApp ONTAP cluster up to 12 HA pairs (24 nodes) in a single cluster. Using the FlexGroup technology described in this solution, a 24-node AFF A90 cluster can provide over 75 PB and up to 550 GBps throughput in a single namespace. Other NetApp storage systems such as the AFF A1K, and A70 offer other performance and capacity options for deployments from small to large. Because ONTAP 9 supports mixed-model clusters, customers can start with a smaller initial footprint and add more or larger storage systems to the cluster as capacity and performance requirements grow. The table below shows a rough estimate of the number of A100 and H100 GPUs supported on each AFF model.

_NetApp storage system sizing guidance_
image:aipod_nv_A90_sizing.png[Error: Missing Graphic Image]
