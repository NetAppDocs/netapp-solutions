---
sidebar: sidebar
permalink: ai/rag_nemo_ingest_netapp_data.html
keywords: RAG, Retrieval Augmented Generation, NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NeMo, NIM, NIMS, Hybrid, Hybrid Cloud, Hybrid Multicloud, NetApp ONTAP, FlexCache, SnapMirror, BlueXP
summary: Enterprise RAG with NetApp - Ingest Existing NetApp Data with NeMo Retriever
---

= Ingest Existing NetApp Data with NeMo Retriever
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./../media/

[.lead]
The NeMo Embedding microservice, part of NVIDIA NeMo Retriever, can be utilized to ingest data into the RAG vector store/knowledge base. This section describes the tasks that need to be performed in order to ingest data from existing NetApp data sources.

== Ingest Data using NVIDIA Sample Chat Bot

You can ingest existing files using the sample chat bot web application that is deployed by the NVIDIA Enterprise RAG LLM Operator. The process for ingesting existing files using the chat bot web application is outlined in this link:https://netapp.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=f718b504-d89b-497e-bd25-b13400d0bfbf&start=57[demo video.]

== Ingest Data Programmatically

You can programmatically ingest large amounts of data using the RAG query server that is deployed by the NVIDIA Enterprise RAG LLM Operator.

The RAG query server's API is automatically exposed via a Kubernetes service as shown in the output of the following command.

```
$ kubectl -n rag-sample get service chain-server
NAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
chain-server   ClusterIP   10.233.28.129   <none>        8081/TCP   59d
```

By default, the service type is ClusterIP, so the API endpoint can only be accessed from inside of the Kubernetes cluster. The service type can be changed by modifying the `query.service.type` field in your helm pipeline config (for example, helmpipeline_app.yaml). 

The API server swagger schema can be accessed at `<chain_server_url>:<chain_server_api_port>/docs``.
