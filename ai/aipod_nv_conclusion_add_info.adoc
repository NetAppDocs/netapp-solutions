---
sidebar: sidebar
permalink: ai/aipod_nv_conclusion_add_info.html
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX
summary: NetApp AIPod with NVIDIA DGX Systems - Where to Find Additional Information
---

= NetApp AIPod with NVIDIA DGX Systems - Conclusion and Additional Information
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./../media/

== Conclusion

The DGX BasePOD architecture is a next-generation deep learning platform that requires equally advanced storage and data management capabilities. By combining DGX BasePOD with NetApp AFF systems, the NetApp AIPod with DGX systems architecture can be implemented at almost any scale up to 48 DGX H100 systems on a 24-node AFF A900 cluster. Combined with the superior cloud integration and software-defined capabilities of NetApp ONTAP, AFF enables a full range of data pipelines that spans the edge, the core, and the cloud for successful DL projects.

== Additional Information
To learn more about the information described in this document, please refer to the following documents and/or websites:

* NetApp ONTAP data management software â€” ONTAP information library
+
https://docs.netapp.com/us-en/ontap-family/[https://docs.netapp.com/us-en/ontap-family/^]

* NetApp AFF A900 storage systems-
+
https://www.netapp.com/data-storage/aff-a-series/aff-a900/[https://www.netapp.com/data-storage/aff-a-series/aff-a900/]

* NetApp ONTAP RDMA information-
+
link:https://docs.netapp.com/us-en/ontap/nfs-rdma/index.html[https://docs.netapp.com/us-en/ontap/nfs-rdma/index.html]

* NetApp DataOps Toolkit
+
https://github.com/NetApp/netapp-dataops-toolkit[https://github.com/NetApp/netapp-dataops-toolkit^]

* NetApp Astra Trident
+
https://docs.netapp.com/us-en/netapp-solutions/containers/rh-os-n_overview_trident.html[https://docs.netapp.com/us-en/netapp-solutions/containers/rh-os-n_overview_trident.html^]

* NetApp GPUDirect Storage Blog-
+
https://www.netapp.com/blog/ontap-reaches-171-gpudirect-storage/[https://www.netapp.com/blog/ontap-reaches-171-gpudirect-storage/]

* NVIDIA DGX BasePOD
+
https://www.nvidia.com/en-us/data-center/dgx-basepod/[https://www.nvidia.com/en-us/data-center/dgx-basepod/^]

* NVIDIA DGX H100 systems
+
https://www.nvidia.com/en-us/data-center/dgx-h100/[https://www.nvidia.com/en-us/data-center/dgx-h100/^]

* NVIDIA Networking
+
https://www.nvidia.com/en-us/networking/[https://www.nvidia.com/en-us/networking/^]

* NVIDIA Magnum IO GPUDirect Storage
+
https://docs.nvidia.com/gpudirect-storage[https://docs.nvidia.com/gpudirect-storage]

* NVIDIA Base Command
+
https://www.nvidia.com/en-us/data-center/base-command/[https://www.nvidia.com/en-us/data-center/base-command/]

* NVIDIA Base Command Manager
+
https://www.nvidia.com/en-us/data-center/base-command/manager[https://www.nvidia.com/en-us/data-center/base-command/manager]

* NVIDIA AI Enterprise 
+
https://www.nvidia.com/en-us/data-center/products/ai-enterprise/[https://www.nvidia.com/en-us/data-center/products/ai-enterprise/^]

== Acknowledgements

This document is the work of the NetApp Solutions and ONTAP Engineering teams- David Arnette, Olga Kornievskaia, Dustin Fischer, Srikanth Kaligotla, Mohit Kumar and Rajeev Badrinath. The authors would also like to thank NVIDIA and the NVIDIA DGX BasePOD engineering team for their continued support. 
