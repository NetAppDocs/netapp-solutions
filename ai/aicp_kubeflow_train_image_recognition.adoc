---
sidebar: sidebar
permalink: ai/aicp_kubeflow_train_image_recognition.html
keywords: Jupyter Notebook, Kubeflow Pipeline, NetApp DataOps Toolkit, MNIST, Image Recognition
summary: Open Source MLOps with NetApp - Example Workflow - Train an Image Recognition Model Using Kubeflow and the NetApp DataOps Toolkit
---

= Example Workflow - Train an Image Recognition Model Using Kubeflow and the NetApp DataOps Toolkit
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./../media/

[.lead]
This section describes the steps involved in training and deploying a Neural Network for Image Recognition using Kubeflow and the NetApp DataOps Toolkit. This is intended to serve as an example to show a training job that incorporates NetApp storage. 

== Prerequisites

Create a Dockerfile with the required configurations to use for the train and test steps within the Kubeflow pipeline. 
Here is an example of a Dockerfile - 
```
FROM pytorch/pytorch:latest
RUN pip install torchvision numpy scikit-learn matplotlib tensorboard
WORKDIR /app
COPY . /app
COPY train_mnist.py /app/train_mnist.py
CMD ["python", "train_mnist.py"]
```
Depending on your requirements, install all required libraries and packages needed to run the program. Before you train the Machine Learning model, it is assumed that you already have a working Kubeflow deployment.



== Train a Small NN on MNIST Data Using PyTorch and Kubeflow Pipelines

We use the example of a small Neural Network trained on MNIST data. The MNIST dataset consists of handwritten images of digits from 0-9. The images are 28x28 pixels in size. The dataset is divided into 60,000 train images and 10,000 validation images. The Neural Network used for this experiment is a 2-layer feedforward network. Training is executed using Kubeflow Pipelines. Refer to the documentation https://www.kubeflow.org/docs/components/pipelines/v1/introduction/[here^] for more information. Our Kubeflow pipeline incorporates the docker image from the Prerequisites section. 

image:kubeflow_pipeline.png[Kubeflow Pipeline Run Visualization]

== Visualize Results Using Tensorboard

Once the model is trained, we can visualize the results using Tensorboard. https://www.tensorflow.org/tensorboard[Tensorboard^] is available as a feature on the Kubeflow Dashboard. You can create a custom tensorboard for your job. An example below shows the plot of training accuracy vs. number of epochs and training loss vs. number of epochs. 

image:tensorboard_graph.png[Tensorboard graph for training loss and accuracy]

== Experiment with Hyperparameters Using Katib
https://www.kubeflow.org/docs/components/katib/hyperparameter/[Katib^] is a tool within Kubeflow that can be used to experiment with the model hyperparameters. To create an experiment, define a desired metric/goal first. This is usually the test accuracy. Once the metric is defined, choose hyperparameters that you would like to play around with (optimizer/learning_rate/number of layers). Katib does a hyperparameter sweep with the user-defined values to find the best combination of parameters that satisfy the desired metric. You can define these parameters in each section in the UI. Alternatively, you could define a *YAML* file with the necessary specifications. Below is an illustration of a Katib experiment - 

image:katib_experiment_1.png[Katib Experiment Dashboard with hyperparameters]

image:katib_experiment_2.png[Successful trial check]

== Use NetApp Snapshots to Save Data for Traceability

During the model training, we may want to save a snapshot of the training dataset for traceability. To do this, we can add a snapshot step to the pipeline as shown below. To create the snapshot, we can use the https://github.com/NetApp/netapp-dataops-toolkit/tree/main/netapp_dataops_k8s[NetApp DataOps Toolkit for Kubernetes^].

image:kubeflow_snapshot.png[Code to build a Snapshot pipeline in Kubeflow]

Refer to the https://github.com/NetApp/netapp-dataops-toolkit/tree/main/netapp_dataops_k8s/Examples/Kubeflow[NetApp DataOps Toolkit example for Kubeflow^] for more information.
