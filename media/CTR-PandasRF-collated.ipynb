{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook does the following:\n",
    "1. Load Criteo Terabyte Click Logs Day 15 as Pandas DF\n",
    "2. Process and format data\n",
    "3. Train a Scikit-learn random forest model\n",
    "4. Perform prediction & calculate accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "pandas, numpy, sklearn.model_selection, sklearn.metrics, matplotlib, matplotlib.pyplot\n",
    "\n",
    "Download Criteo Click Logs dataset Day 15 in Terminal:\n",
    "wget http://azuremlsampleexperiments.blob.core.windows.net/criteo/day_15.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/envs/rapids/lib/python3.7/site-packages (1.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/rapids/lib/python3.7/site-packages (1.19.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/rapids/lib/python3.7/site-packages (3.3.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from matplotlib) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/rapids/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/rapids/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: sklearn in /opt/conda/envs/rapids/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/rapids/lib/python3.7/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.19.4)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.19.4)\n"
     ]
    }
   ],
   "source": [
    "# optional installation if the following libraries have not been installed in the cluster:\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/data/day_15' #after download the dataset, decompressed the file first. day_15 is text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t2\t9\t\t1\t\t0\t0\t3\t1\t0\t\t1036\t\t4db5cd76\t310b1fd7\tbfbe69f6\tbc892e1f\t1315f676\t6fcd6dcb\te7222fbe\tb2a2bd17\t25dd8f9a\t2d40282b\t4f91b406\ta81c2672\ta77a4a56\tbe4ee537\t57469cbd\t4cdc3efa\t1f7fc70b\tb8170bba\t9512c20b\t31a9f3b3\t228aee9b\tb74c6548\t59f9dd38\t165fbf32\t0b3c06d0\t2ccea557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#readline() is reading the first 1 line.\n",
    "with open(file) as f:\n",
    "    print(f.readline()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1\t3\t0\t7\t5\t0\t0\t3575\t6\t0\t4\t11976\t1\tf438eac0\te7c8f4b4\t5b913d0f\tf2463ffb\t729e35ab\t6fcd6dcb\t27f43f86\t312aa74b\t25dd8f9a\t96bd225a\t3861b8d7\tf1b49bb9\ta77a4a56\t672e9cf8\t96fd88a3\tae30c32c\t1f7fc70b\tb6bc86c5\t108a0699\t5865ea16\td55ec182\tf11ef8d0\t483383ee\td7b3dff0\t321935cd\t2ba8d787\n",
      "\n",
      "Accuracy: 0.96592\n",
      "CPU times: user 43min 50s, sys: 26.8 s, total: 44min 17s\n",
      "Wall time: 47min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "header = ['col'+str(i) for i in range (1,41)] #note that according to criteo, the first column in the dataset is Click Through (CT). Consist of 40 columns \n",
    "\n",
    "first_row_taken = 50_000_000 # use this in pd.read_csv() if your compute resource is limited.\n",
    "# total number of rows in day15 is 20B\n",
    "# take 20M, 30M \n",
    "\n",
    "\"\"\"\n",
    "Read data & display the following metrics:\n",
    "1. Total number of rows per day\n",
    "2. df loading time in the cluster \n",
    "3. Train a random forest model\n",
    "\"\"\" \n",
    "df = pd.read_csv(file, nrows=first_row_taken, delimiter='\\t', names=header)\n",
    "\n",
    "# take numerical columns\n",
    "df_sliced = df.iloc[:, 0:14]\n",
    "\n",
    "# split data into training and Y\n",
    "Y = df_sliced.pop('col1') # first column is binary (click or not)\n",
    "\n",
    "# change df_sliced data types & fillna\n",
    "df_sliced = df_sliced.astype(np.float32).fillna(0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest building parameters\n",
    "# n_streams = 8 # optimization\n",
    "max_depth = 10\n",
    "n_bins = 16\n",
    "n_trees = 10\n",
    "\n",
    "rf_model = RandomForestClassifier(max_depth=max_depth, n_estimators=n_trees)\n",
    "rf_model.fit(df_sliced, Y)\n",
    "\n",
    "# testing data, last 1M rows in day15\n",
    "test_file = '/data/day_15_test'\n",
    "with open(test_file) as g:\n",
    "    print(g.readline()) \n",
    "    \n",
    "# dataFrame processing for test data\n",
    "test_df = pd.read_csv(test_file, delimiter='\\t', names=header) \n",
    "test_df_sliced = test_df.iloc[:, 0:14]\n",
    "test_Y = test_df_sliced.pop('col1')\n",
    "test_df_sliced = test_df_sliced.astype(np.float32).fillna(0)\n",
    "\n",
    "# prediction & calculating error\n",
    "pred_df = rf_model.predict(test_df_sliced)\n",
    "\n",
    "from sklearn import metrics\n",
    "# Model Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_Y, pred_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: https://labs.criteo.com/2013/12/download-terabyte-click-logs/\n",
    "\n",
    "Project Inspiration:https://towardsdatascience.com/mobile-ads-click-through-rate-ctr-prediction-44fdac40c6ff\n",
    "\n",
    "Mapping object to set of Integer wiht Hash Function, before using it in XGBoost: https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087\n",
    "\n",
    "Regularization, Variance, OverFit Concept: https://www.youtube.com/watch?v=Q81RR3yKn30\n",
    "\n",
    "XGBoost_Playlist by StatQuest: https://www.youtube.com/watch?v=OtD8wVaFm6E&list=PLblh5JKOoLULU0irPgs1SnKO6wqVjKUsQ\n",
    "\n",
    "Visulazing XGBClassifier with val_metric Error & LogLoss: https://setscholars.net/wp-content/uploads/2019/02/visualise-XgBoost-model-with-learning-curves-in-Python.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
