---
sidebar: sidebar
permalink: data-analytics/hdcs-sh-hadoop-data-protection-and-netapp.html
keywords: distcp, copy, backup workflow, hdfs, mapreduce
summary: Hadoop DistCp is a native tool used for large intercluster and intracluster copying. The Hadoop DistCp basic process is a typical backup workflow using Hadoop native tools such as MapReduce to copy Hadoop data from an HDFS source to a corresponding target.
---

= Hadoop data protection and NetApp
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./../media/

//
// This file was created with NDAC Version 2.0 (August 17, 2020)
//
// 2021-10-28 12:57:46.888587
//

link:hdcs-sh-data-fabric-powered-by-netapp-for-big-data-architecture.html[Previous: Data fabric powered by NetApp for big data architecture.]

[.lead]
Hadoop DistCp is a native tool used for large intercluster and intracluster copying. The Hadoop DistCp basic process shown in the figure below is a typical backup workflow using Hadoop native tools such as MapReduce to copy Hadoop data from an HDFS source to a corresponding target. The NetApp NFS direct access enables customers to set NFS as the target destination for the Hadoop DistCp tool to copy the data from HDFS source into an NFS share through MapReduce. The NetApp NFS direct access acts as an NFS driver for the DistCp tool.

image:hdcs-sh-image4.png[Error: Missing Graphic Image]

link:hdcs-sh-overview-of-hadoop-data-protection-use-cases.html[Next: Overview of Hadoop data protection use cases.]
