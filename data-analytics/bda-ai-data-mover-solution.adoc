---
sidebar: sidebar
permalink: data-analytics/bda-ai-data-mover-solution.html
keywords: data, mover, hdfs, mapr-fs, s3, spark
summary: In a big-data cluster, data is stored in HDFS or HCFS, such as MapR-FS, the Windows Azure Storage Blob, S3, or the Google file system. We performed testing with HDFS, MapR-FS, and S3 as the source to copy data to NetApp ONTAP NFS export with the help of NIPAM by using the hadoop distcp command from the source.
---

= Data mover solution
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./../media/

//
// This file was created with NDAC Version 2.0 (August 17, 2020)
//
// 2022-02-03 19:40:46.780656
//

link:bda-ai-customer-challenges.html[Previous: Customer challenges.]

[.lead]
In a big-data cluster, data is stored in HDFS or HCFS, such as MapR-FS, the Windows Azure Storage Blob, S3, or the Google file system. We performed testing with HDFS, MapR-FS, and S3 as the source to copy data to NetApp ONTAP NFS export with the help of NIPAM by using the `hadoop distcp` command from the source.

The following diagram illustrates the typical data movement from a Spark cluster running with HDFS storage to a NetApp ONTAP NFS volume so that NVIDIA can process AI operations.

image:bda-ai-image3.png[Error: Missing Graphic Image]

The `hadoop distcp` command uses the MapReduce program to copy the data. NIPAM works with MapReduce to act as a driver for the Hadoop cluster when copying data. NIPAM can distribute a load across multiple network interfaces for a single export. This process maximizes the network throughput by distributing the data across multiple network interfaces when you copy the data from HDFS or HCFS to NFS.

[NOTE]
NIPAM is not supported or certified with MapR.

link:bda-ai-data-mover-solution-for-ai.html[Next: Data mover solution for AI.]
