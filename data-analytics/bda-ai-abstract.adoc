---
sidebar: sidebar
permalink: data-analytics/bda-ai-abstract.html
keywords:
summary:
---

= Abstract
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/

//
// This file was created with NDAC Version 2.0 (August 17, 2020)
//
// 2022-02-03 19:40:46.766715
//

[.lead]
This document describes how to move data from big-data analytics and high-performance computing (HPC) systems so that it can be used in artificial intelligence (AI) workflows. AI typically processes NFS data through NFS exports. However, you might have your AI data in a big-data-analytics and high-performance-computing (HPC) platform. This could be the Hadoop Distributed File System (HDFS), a binary large object (Blob), S3 storage,  or IBMâ€™s General Parallel File System (GPFS). In this document, we describe how to move data from a big-data analytics platform and GPFS to NFS using Hadoop-native commands, the NetApp In-Place Analytics Module (NIPAM), and NetApp XCP. This document also discusses the business benefits of moving data from big data and HPC to AI.
