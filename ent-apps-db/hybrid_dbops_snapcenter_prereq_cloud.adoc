---
sidebar: sidebar
permalink: ent-apps-db/hybrid_dbops_snapcenter_prereq_cloud.html
summary: hybrid cloud database solutions with SnapCenter cloud prerequisites
keywords: netapp, solutions, database, SnapCenter, "getting started", cloud, prerequisites
---

= Hybrid Cloud Database Workflow Prerequisites
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:table-stripes: odd
:imagesdir: ./../media/

[.lead]
Before we install the Cloud Manager connector, Cloud Volumes ONTAP and configure SnapMirror, we will need to perform some preperation on our cloud environment of choice. This page describes the work that needs to be done as well as the considerations when deploying Cloud Volumes ONTAP.

=== Cloud Manager & Cloud Volumes ONTAP deployment prerequisites Checklist

[%interactive]
* [ ] A NetApp Cloud Central login
* [ ] Network access from a web browser to several endpoints
* [ ] A network location for a Connector
* [ ] Cloud provider permissions
* [ ] Networking for individual services

For more information about what you need to get started, please visit our https://docs.netapp.com/us-en/occm/reference_checklist_cm.html[cloud documentation^].

== Considerations

=== 1. What is a Cloud Manager Connector?

In most cases, a Cloud Central Account Admin will need to deploy a Connector in your cloud or on-premises network. The Connector enables Cloud Manager to manage resources and processes within your public cloud environment.

For more information about Connectors, please visit our https://docs.netapp.com/us-en/occm/concept_connectors.html[cloud documentation^].

=== 2. Cloud Volumes ONTAP sizing and architecture

When deploying Cloud Volumes ONTAP, you will be given the option to choose either a pre-defined package or create your own configuration. Although many of these values can be changed later on non-disruptively, there are some key considerations that need to be made before deployment based on the workloads that will be deployed in the cloud.

Each cloud provider has different options for deplyment and almost every workload has its own unique properties. NetApp has a https://cloud.netapp.com/cvo-sizer[CVO sizing tool^] that can help size deployments correctly based on capacity and performance, but it has been built around some basic concepts which are worth considering:

- Capacity required
- Network capability of cloud virtual machine
- Performance characteristics of cloud storage

The key is to plan for a configuration that not only satisfies the current capacity and performance requirements, but also looks at future growth. This is generally known as capacity headroom and performance headroom.

If you would like some further information, please read the documentation about planning correctly for https://docs.netapp.com/us-en/occm/task_planning_your_config.html[AWS^], https://docs.netapp.com/us-en/occm/task_planning_your_config_azure.html[Azure^] and https://docs.netapp.com/us-en/occm/task_planning_your_config_gcp.html[GCP^].

=== 3. Single Node or High Availability?

In all clouds, there is the option to deploy CVO in either a single node or clustered high availability pair with 2 nodes. Depending on the use case, you may wish to deploy a single node to save costs or an HA pair to provide further availability and redundancy.

For a DR use case or spinning up temporary storage for development and testing, single nodes are common since the impact of a sudden zonal or infrastructure outage is lower. However, for any production use case, or where the data is only in a single location, or the dataset must have more redundancy and availability, high availability is recommended.

For further information about the architecture of each cloud's version of high availability, please visit the documentation for https://docs.netapp.com/us-en/occm/concept_ha.html[AWS^], https://docs.netapp.com/us-en/occm/concept_ha_azure.html[Azure^] and https://docs.netapp.com/us-en/occm/concept_ha_google_cloud.html[GCP^].
