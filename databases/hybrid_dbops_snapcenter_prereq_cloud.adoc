---
sidebar: sidebar
permalink: databases/hybrid_dbops_snapcenter_prereq_cloud.html
summary: Before we install the Cloud Manager connector and Cloud Volumes ONTAP and configure SnapMirror, we must perform some preparation for our cloud environment. This page describes the work that needs to be done as well as the considerations when deploying Cloud Volumes ONTAP.
keywords: prerequisites, aws, azure, gcp, cloud central, cloud volumes ontap
---
= Prerequisites for the public cloud
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:table-stripes: odd
:imagesdir: ./../media/

[.lead]
Before we install the Cloud Manager connector and Cloud Volumes ONTAP and configure SnapMirror, we must perform some preparation for our cloud environment. This page describes the work that needs to be done as well as the considerations when deploying Cloud Volumes ONTAP.

== Cloud Manager and Cloud Volumes ONTAP deployment prerequisites checklist

[%interactive]
* [ ] A NetApp Cloud Central login
* [ ] Network access from a web browser to several endpoints
* [ ] A network location for a Connector
* [ ] Cloud provider permissions
* [ ] Networking for individual services

For more information about what you need to get started, visit our https://docs.netapp.com/us-en/occm/reference_checklist_cm.html[cloud documentation^].

== Considerations

=== 1. What is a Cloud Manager connector?

In most cases, a Cloud Central account admin must deploy a connector in your cloud or on-premises network. The connector enables Cloud Manager to manage resources and processes within your public cloud environment.

For more information about Connectors, visit our https://docs.netapp.com/us-en/occm/concept_connectors.html[cloud documentation^].

=== 2. Cloud Volumes ONTAP sizing and architecture

When deploying Cloud Volumes ONTAP, you are given the choice of either a predefined package or the creation of your own configuration. Although many of these values can be changed later on nondisruptively, there are some key decisions that need to be made before deployment based on the workloads to be deployed in the cloud.

Each cloud provider has different options for deployment and almost every workload has its own unique properties. NetApp has a https://cloud.netapp.com/cvo-sizer[CVO sizing tool^] that can help size deployments correctly based on capacity and performance, but it has been built around some basic concepts which are worth considering:

* Capacity required
* Network capability of the cloud virtual machine
* Performance characteristics of cloud storage

The key is to plan for a configuration that not only satisfies the current capacity and performance requirements, but also looks at future growth. This is generally known as capacity headroom and performance headroom.

If you would like further information, read the documentation about planning correctly for https://docs.netapp.com/us-en/occm/task_planning_your_config.html[AWS^], https://docs.netapp.com/us-en/occm/task_planning_your_config_azure.html[Azure^], and https://docs.netapp.com/us-en/occm/task_planning_your_config_gcp.html[GCP^].

=== 3. Single node or high availability?

In all clouds, there is the option to deploy CVO in either a single node or in a clustered high availability pair with two nodes. Depending on the use case, you might wish to deploy a single node to save costs or an HA pair to provide further availability and redundancy.

For a DR use case or spinning up temporary storage for development and testing, single nodes are common since the impact of a sudden zonal or infrastructure outage is lower. However, for any production use case, when the data is in only a single location, or when the dataset must have more redundancy and availability, high availability is recommended.

For further information about the architecture of each cloud's version of high availability, visit the documentation for https://docs.netapp.com/us-en/occm/concept_ha.html[AWS^], https://docs.netapp.com/us-en/occm/concept_ha_azure.html[Azure^] and https://docs.netapp.com/us-en/occm/concept_ha_google_cloud.html[GCP^].
