---
sidebar: sidebar
permalink: databases/automation_ora_asa_iscsi.html
keywords: Database, Oracle, ASA, ONTAP, NetApp ASA
summary: "The solution provides overview and details for automated Oracle deployment and protection in NetApp ASA array as primary database storage with iSCSI protocol and Oracle database configured in standalone ReStart using asm as volume manager." 
---

= TR-4983: Simplified, Automated Oracle Deployment on NetApp ASA with iSCSI
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./../media/

Allen Cao, Niyaz Mohamed, NetApp

[.lead]
== Purpose

NetApp ASA systems deliver modern solutions to your SAN infrastructure. They simplify at scale and enable you to accelerate your business-critical applications such as database, make sure that your data is always available (99.9999% uptime), and reduce TCO and carbon footprint. The NetApp ASA systems include A-Series models designed for the most performance-demanding applications, and C-Series models optimized for cost-effective, large-capacity deployments. Together, the ASA A-Series and C-Series systems deliver exceptional performance to improve customer experience and reduce time to results, keep business-critical data available, protected, and secure, and provide more effective capacity for any workload, backed by the industryâ€™s most effective guarantee.

This documentation demonstrates simplified deployment of Oracle databases in a SAN environment built with ASA systems using Ansible automation. The Oracle database is deployed in a standalone ReStart configuration with iSCSI protocol for data access and Oracle ASM for storage management on ASA storage array. We also demonstrate how to use the NetApp SnapCenter UI tool to backup, restore, and clone an Oracle database for dev/test or other use cases for storage-efficient database operation in NetApp ASA systems. 


This solution addresses the following use cases:

* Automated Oracle database deployment in NetApp ASA systems as primary database storage 
* Oracle database backup and restore in NetApp ASA systems using NetApp SnapCenter tool 
* Oracle database clone for dev/test or other use cases in NetApp ASA systems using NetApp SnapCenter tool

== Audience

This solution is intended for the following people:

* A DBA who would like to deploy Oracle in NetApp ASA systems.
* A database solution architect who would like to test Oracle workloads in NetApp ASA systems.
* The storage administrator who would like to deploy and manage an Oracle database on NetApp ASA systems.
* The application owner who would like to stand up an Oracle database in NetApp ASA systems.

== Solution test and validation environment

The testing and validation of this solution was performed in a lab setting that might not match the final deployment environment. For more information, see the section <<Key Factors for Deployment Consideration>>.

=== Architecture

image::automation_ora_asa_iscsi_archit.png["This image provides a detailed picture of the Oracle deployment configuration in AWS public cloud with iSCSI and ASM."]

=== Hardware and software components

[width=100%,cols="33%, 33%, 33%", frame=none, grid=rows]
|===
3+^| *Hardware*
| NetApp ASA A400 | Version 9.13.1P1 | 2 NS224 shelves, 48 NVMe AFF drives with total 69.3 TiB capacity
| UCSB-B200-M4 |  | Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz | 4-node VMware ESXi cluster 

3+^| *Software*
| RedHat Linux | RHEL-8.6, 4.18.0-372.9.1.el8.x86_64 kernel | Deployed RedHat subscription for testing
| Windows Server | 2022 Standard, 10.0.20348 Build 20348 | Hosting SnapCenter server 
| Oracle Grid Infrastructure | Version 19.18 | Applied RU patch p34762026_190000_Linux-x86-64.zip
| Oracle Database | Version 19.18 | Applied RU patch p34765931_190000_Linux-x86-64.zip
| Oracle OPatch | Version 12.2.0.1.36 | Latest patch p6880880_190000_Linux-x86-64.zip
| SnapCenter Server | Version 4.9P1 | Workgroup deployment 
| VMware vSphere Hypervisor | version 6.5.0.20000 | VMware Tools, Version: 11365 - Linux, 12352 - Windows 
| Open JDK | Version java-1.8.0-openjdk.x86_64 | SnapCenter plugin requirement on DB VMs 
|===

=== Oracle Database configuration in lab environment

[width=100%,cols="33%, 33%, 33%", frame=none, grid=rows]
|===
3+^| 
| *Server* | *Database* | *DB Storage*
| ora_01 | cdb1(cdb1_pdb1,cdb1_pdb2,cdb1_pdb3) | iSCSI luns on ASA A400
| ora_02 | cdb3(cdb3_pdb1,cdb3_pdb2,cdb3_pdb3) | iSCSI luns on ASA A400
|===

=== Key factors for deployment consideration

* *Oracle database storage layout.* In this automated Oracle deployment, we provision four database volumes to host Oracle binary, data, and logs by default. We then create two ASM disk groups from data and logs luns. Within the +DATA asm disk group, we provision two data luns in a volume on each ASA A400 cluster node. Within the +LOGS asm disk group, we create two luns in a logs volume on a single ASA A400 node. Multiple luns laid out within an ONTAP volume provides better performance in general. 

* *Multiple DB servers deployment.* The automation solution can deploys an Oracle container database to multiple DB servers in a single Ansible playbook run. Regardless of the number of DB servers, the playbook execution remains the same. In the event of multi-DB server deployments, the playbook builds with an algorithm to place database luns on dual controllers of ASA A400 optimally. The binary and logs luns of odd number DB server in server hosts index place on controller 1. The binary and logs luns of even number DB server in the server hosts index place on controller 2. The DB data luns evenly distribute to two controllers. Oracle ASM combines the data luns on two controllers into a single ASM disk group to fully utilize the processing power of both controllers. 

* *iSCSI configuration.* The database VMs connect to ASA storage with the iSCSI protocol for storage access. You should configure dual paths on each controller node for redundancy and setup iSCSI multi-path on the DB server for  multi-path storage access. Enable jumbo frame on storage network to maximize performance and throughput. 

* *Oracle ASM redundancy level to use for each Oracle ASM disk group that you create.* Because the ASA A400 configure storage in RAID DP for data protection at the cluster disk level, you should use `External Redundancy`, which means that the option does not allow Oracle ASM to mirror the contents of the disk group.

* *Database backup.* NetApp provides a SnapCenter software suite for database backup, restore, and clone with an user friendly UI interface. NetApp recommends implementing such a management tool to achieve fast (under a minute) SnapShot backup, quick (minutes) database restore, and database clone.    

== Solution deployment

The following sections provide step-by-step procedures for automated Oracle 19c deployment and protection in NetApp ASA A400 with directly mounted database luns via iSCSI to DB VM in a single node Restart configuration with Oracle ASM as database volume manager.     

=== Prerequisites for deployment
[%collapsible]
====

Deployment requires the following prerequisites.

. It is assumed that NetApp ASA storage array has been installed and configured. This includes iSCSI broadcast domain, LACP interface groups a0a on both controller nodes, iSCSI VLAN ports (a0a-<iscsi-a-vlan-id>, a0a-<iscsi-b-vlan-id>) on both controller nodes. Following link provides detailed step by step instructions if help is needed. link:https://docs.netapp.com/us-en/ontap-systems/asa400/install-detailed-guide.html[Detailed guide - ASA A400^]

. Provision a Linux VM as Ansible controller node with latest version of Ansible and Git installed. Refer to following link for details: link:https://review.docs.netapp.com/us-en/netapp-solutions_acao_ora_vmc/automation/getting-started.html[Getting Started with NetApp solution automation^] in section - `Setup the Ansible Control Node for CLI deployments on RHEL / CentOS` or `Setup the Ansible Control Node for CLI deployments on Ubuntu / Debian`. 

. Clone a copy of NetApp Oracle deployment automation toolkit for iSCSI. 
+
[source, cli]
git clone https://github.com/NetApp-Automation/na_oracle_deploy_iscsi.git

. Provision a Windows server to run NetApp SnapCenter UI tool with latest version. Refer to following link for details: link:https://docs.netapp.com/us-en/snapcenter/install/task_install_the_snapcenter_server_using_the_install_wizard.html[Install the SnapCenter Server^]

. Build two RHEL Oracle DB servers either bare metal or virtualized VM. Create a admin user on DB servers with sudo without password privilege and enable ssh private/public key authentication between Ansible host and Oracle DB servers hosts. Stage following Oracle 19c installation files on DB servers /tmp/archive directory.
+
      installer_archives:
        - "LINUX.X64_193000_grid_home.zip"
        - "p34762026_190000_Linux-x86-64.zip"
        - "LINUX.X64_193000_db_home.zip"
        - "p34765931_190000_Linux-x86-64.zip"
        - "p6880880_190000_Linux-x86-64.zip"
+
[NOTE]

Ensure that you have allocated at least 50G in Oracle VM root volume in order to have sufficient space to stage Oracle installation files.

. Watch following video:


====

=== Automation parameter files
[%collapsible]

====

Ansible playbook executes database installation and configuration tasks with predefined parameters. For this Oracle automation solution, there are three user defined parameter files that needs user inputs before playbook execution.

* hosts - define targets that the automation playbook is running against.
* vars.yml - global variable file that defines variables that apply to all targets.
* host_name.yml - local variable file that defines variables that apply only to local target. In our use case, these are the Oracle DB servers. 

In additional to these user defined variable files, there are number of default variable files that contains default parameters that do not require change unless necessary. Following sections show how the user defined variable files are configured. 

====

=== Parameter files configuration
[%collapsible]

====

. Ansible target hosts file configuration:
+
include::../_include/automation_ora_asa_iscsi_hosts.adoc[]

. Global vars.yml file configuration
+
include::../_include/automation_ora_asa_iscsi_vars.adoc[]

. Local DB server host_name.yml configuration
+
include::../_include/automation_ora_asa_iscsi_host_vars.adoc[]

====

=== Playbook execution
[%collapsible]

====

There are total five playbooks in automation toolkit. Each performs different tasks blocks and serves different purposes.

      0-all_playbook.yml - execute playbooks from 1-4 in one playbook run.
      1-ansible_requirements.yml - setup Ansible controller with required libs and collections.
      2-linux_config.yml - execute Linux kernel configuration on Oracle DB servers.
      3-ontap_config.yml - configure ONTAP for Oracle database including creation of SVM, data volumes/luns provision, host igroup setup etc.  
      4-oracle_config.yml - install and configure Oracle on DB servers for grid infrastructure and container database creation. 
      5-destroy.yml - optional to undo the environment to dismantle all. 

There are three options to run the playbooks with following commands. 

. Execute all playbook in one run.
+
[source, cli]
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml

. Execute playbooks one at a time with the number of sequence from 1-4.
+
[source, cli]] 
ansible-playbook -i hosts 1-ansible_requirements.yml -u admin -e @vars/vars.yml
+
[source, cli] 
ansible-playbook -i hosts 2-linux_config.yml -u admin -e @vars/vars.yml
+
[source, cli]
ansible-playbook -i hosts 3-ontap_config.yml -u admin -e @vars/vars.yml
+
[source, cli]
ansible-playbook -i hosts 4-oracle_config.yml -u admin -e @vars/vars.yml

. Execute all playbook with a tag.
+
[source, cli]
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t ansible_requirements
+
[source, cli]
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t linux_config
+
[source, cli]
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t ontap_config
+
[source, cli]
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t oracle_config

. Undo the environment
+
[source, cli]
ansible-playbook -i hosts 5-destroy.yml -u admin -e @vars/vars.yml


====

=== Post execution validation
[%collapsible]

====


====





=== Oracle backup, restore, and clone with SnapCenter
[%collapsible]

====

====


== Where to find additional information

To learn more about the information described in this document, review the following documents and/or websites:

* NETAPP ASA: ALL-FLASH SAN ARRAY
+
link:https://www.netapp.com/data-storage/all-flash-san-storage-array/[https://www.netapp.com/data-storage/all-flash-san-storage-array/^]

* Installing Oracle Grid Infrastructure for a Standalone Server with a New Database Installation 
+
link:https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/installing-oracle-grid-infrastructure-for-a-standalone-server-with-a-new-database-installation.html#GUID-0B1CEE8C-C893-46AA-8A6A-7B5FAAEC72B3[https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/installing-oracle-grid-infrastructure-for-a-standalone-server-with-a-new-database-installation.html#GUID-0B1CEE8C-C893-46AA-8A6A-7B5FAAEC72B3^]

*  Installing and Configuring Oracle Database Using Response Files
+
link:https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/installing-and-configuring-oracle-database-using-response-files.html#GUID-D53355E9-E901-4224-9A2A-B882070EDDF7[https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/installing-and-configuring-oracle-database-using-response-files.html#GUID-D53355E9-E901-4224-9A2A-B882070EDDF7^]


* Use Red Hat Enterprise Linux 8.2 with ONTAP
+
link:https://docs.netapp.com/us-en/ontap-sanhost/hu_rhel_82.html#all-san-array-configurations[https://docs.netapp.com/us-en/ontap-sanhost/hu_rhel_82.html#all-san-array-configurations^]



